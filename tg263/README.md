# AnatomInd TG-263 API

Sistema Docker offline para servir modelos locais com dois backends (vLLM e TGI) e uma API em Rust compatÃ­vel com OpenAI, incluindo classificaÃ§Ã£o TG-263.

## ðŸŽ¯ CaracterÃ­sticas

- **100% Offline**: Sem downloads do Hugging Face Hub
- **Dual Backend**: vLLM para GPUs modernas, TGI para NVIDIA P40 (SM 6.1)
- **API OpenAI Compatible**: Endpoints `/v1/chat/completions` e `/v1/completions`
- **ClassificaÃ§Ã£o TG-263**: Endpoint `/classify` com normalizaÃ§Ã£o e ranking via Jaro-Winkler
- **Streaming SSE**: Suporte completo para respostas em tempo real
- **Docker Compose**: OrquestraÃ§Ã£o simples de todos os serviÃ§os

## ðŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   vLLM      â”‚    â”‚     TGI      â”‚    â”‚  Rust API   â”‚
â”‚  :8000      â”‚    â”‚    :8001     â”‚    â”‚   :8080     â”‚
â”‚             â”‚    â”‚              â”‚    â”‚             â”‚
â”‚ GPU Modern  â”‚    â”‚  NVIDIA P40  â”‚    â”‚ OpenAI+TG263â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Quick Start

### 1. ConfiguraÃ§Ã£o Inicial

```bash
# Clonar e navegar
cd tg263/

# Copiar configuraÃ§Ã£o
cp .env.example .env

# Editar configuraÃ§Ãµes (opcional)
# Para NVIDIA P40: PROVIDER=tgi
# Para GPUs modernas: PROVIDER=vllm
vim .env
```

### 2. Subir os ServiÃ§os

```bash
# Build e start
docker compose up --build

# Ou em background
docker compose up -d --build
```

### 3. Testar a API

```bash
# Tornar executÃ¡vel
chmod +x scripts/*.sh

# Executar exemplos
./scripts/run_curl_examples.sh

# Health check
curl http://localhost:8080/healthz
```

## ðŸ“¡ Endpoints da API

### Health & Models

```bash
# Status da API
GET /healthz

# Lista de modelos
GET /v1/models
```

### OpenAI Compatible

```bash
# Chat completions
POST /v1/chat/completions
{
  "messages": [{"role": "user", "content": "Hello"}],
  "stream": false,
  "provider": "tgi|vllm"  // opcional
}

# Text completions  
POST /v1/completions
{
  "prompt": "The heart is",
  "max_tokens": 50,
  "stream": true
}
```

### ClassificaÃ§Ã£o TG-263

```bash
# Classificar estrutura anatÃ´mica
POST /classify
{
  "input": "sphenoid sinus",
  "top_k": 5,
  "provider": "tgi"  // opcional
}

# Resposta
{
  "status": "ok|not_found",
  "mapped_label": "Sinus_Sphenoid",
  "topk": [
    {"label": "Sinus_Sphenoid", "score": 0.95},
    {"label": "VB_T11", "score": 0.23}
  ],
  "raw_output": "Sinus_Sphenoid",
  "provider": "tgi"
}
```

## âš™ï¸ ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente (.env)

```bash
# Provider padrÃ£o
PROVIDER=tgi                    # tgi|vllm

# Thresholds de classificaÃ§Ã£o
ABSTAIN_SIM_THRESHOLD=0.85     # 0.0-1.0
MAX_LABELS=5                   # MÃ¡ximo no top-k
```

### SeleÃ§Ã£o de Provider

1. **Query Parameter**: `?provider=tgi|vllm`
2. **Request Body**: `{"provider": "tgi|vllm"}`
3. **Environment**: `PROVIDER=tgi|vllm`

## ðŸ–¥ï¸ Compatibilidade GPU

### NVIDIA P40 (SM 6.1)
```bash
# ConfiguraÃ§Ã£o recomendada
PROVIDER=tgi
DISABLE_FLASH_ATTENTION=1

# TGI automaticamente usa:
# --disable-custom-kernels
```

### GPUs Modernas (RTX, A100, etc.)
```bash
# ConfiguraÃ§Ã£o recomendada  
PROVIDER=vllm

# vLLM com otimizaÃ§Ãµes completas
```

## ðŸ§  TG-263 Labels

O sistema carrega labels do arquivo `labels/TG263.csv`:

```csv
TG263-Primary Name
Sinus_Sphenoid
VB_T11
A_Subclavian
Lungs
Lig_Hepatogastrc
```

### Processo de ClassificaÃ§Ã£o

1. **GeraÃ§Ã£o**: Prompt determinÃ­stico (temperature=0)
2. **NormalizaÃ§Ã£o**: MinÃºsculas, sem acentos, alfanumÃ©rico
3. **Ranking**: Jaro-Winkler similarity contra labels normalizados
4. **Threshold**: Score >= 0.85 para mapeamento vÃ¡lido
5. **Retorno**: Label oficial ou `not_found`

## ðŸ³ Docker Images

### PrÃ©-construÃ­das (Oficiais)
- `rtmedical/anatomind-engine:Llama-8B` (vLLM)
- `rtmedical/anatomind-engine:Llama-8B-TGI` (TGI)

### Override de Modelo
```bash
# Colocar pesos em ./model/ para override
# Mount point: /opt/model:ro
```

## ðŸ”§ Troubleshooting

### OOM na GPU
```bash
# Reduzir contexto no TGI
docker compose exec tgi \
  text-generation-launcher --model-id /opt/model \
  --max-total-tokens 4096 \
  --disable-custom-kernels
```

### P40 Flash Attention
```bash
# JÃ¡ configurado automaticamente
DISABLE_FLASH_ATTENTION=1
```

### Logs
```bash
# Ver logs de todos os serviÃ§os
docker compose logs -f

# ServiÃ§o especÃ­fico
docker compose logs -f api
docker compose logs -f vllm
docker compose logs -f tgi
```

## ðŸ“Š Monitoramento

### Health Checks
```bash
# API
curl http://localhost:8080/healthz

# vLLM  
curl http://localhost:8000/v1/models

# TGI
curl http://localhost:8001/health
```

### MÃ©tricas
- Health checks automÃ¡ticos no Docker Compose
- Logs estruturados com tracing
- Timeouts configurÃ¡veis

## ðŸ› ï¸ Desenvolvimento

### Build Local
```bash
# Apenas API
cd api/
cargo build --release

# Docker rebuild
docker compose build api
docker compose up api
```

### Adicionar Labels TG-263
```bash
# Editar CSV
vim labels/TG263.csv

# Restart para recarregar
docker compose restart api
```

## ðŸ“‹ Testes de AceitaÃ§Ã£o

- âœ… `GET /healthz` retorna `status: ok` e `labels > 0`
- âœ… `GET /v1/models` lista `tg263-8b`
- âœ… `POST /v1/chat/completions` funciona sem streaming
- âœ… `POST /v1/chat/completions` com `stream:true` entrega SSE + `[DONE]`
- âœ… `POST /classify` retorna estrutura completa com scores

## ðŸ“„ LicenÃ§a

Projeto interno RTMedical - Uso restrito
